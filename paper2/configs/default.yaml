# Default Configuration for RL-PyramidKD

# Experiment settings
experiment:
  name: "rl_pyramidkd_default"
  seed: 42
  device: "cuda"
  num_gpus: 8
  distributed: true
  mixed_precision: true

# Model settings
model:
  teacher:
    backbone: "resnet101"
    pretrained: true
    checkpoint: null
  student:
    backbone: "resnet50"
    pretrained: true
    checkpoint: null
  pyramid:
    layers: ["P2", "P3", "P4", "P5"]
    feature_dim: 256

# RL settings
rl:
  # Policy network
  policy:
    state_dim: 1542  # Auto-computed: 512+4*256+1+4+1
    hidden_dim: 256
    num_layers: 4
    use_lstm: true

  # PPO hyperparameters
  ppo:
    lr: 3.0e-4
    clip_epsilon: 0.2
    value_coef: 0.5
    entropy_coef: 0.01
    gamma: 0.99
    gae_lambda: 0.95
    max_grad_norm: 0.5
    ppo_epochs: 4
    mini_batch_size: 64

  # Environment
  environment:
    lambda_tradeoff: 0.5  # Quality-efficiency trade-off
    max_steps: 4
    layer_costs:
      P2: 4.0
      P3: 2.0
      P4: 1.0
      P5: 0.5

  # Training
  training:
    num_episodes: 1000
    episode_length: 100
    num_parallel_envs: 8
    eval_interval: 10
    save_interval: 50

# GradNorm settings
gradnorm:
  enabled: true
  num_tasks: 4
  alpha: 1.5
  lr_weights: 1.0e-2

# Meta-learning settings
meta_learning:
  enabled: false
  algorithm: "maml"
  inner_lr: 1.0e-3
  outer_lr: 1.0e-4
  num_inner_steps: 5
  num_tasks_per_batch: 3

# Dataset settings
dataset:
  name: "coco"
  data_dir: "/path/to/coco"
  train_split: "train2017"
  val_split: "val2017"
  batch_size: 16
  num_workers: 8
  pin_memory: true

# Distillation settings
distillation:
  loss_type: "mse"  # mse, kl, cosine
  temperature: 4.0
  alpha: 0.5  # Task loss weight
  beta: 0.5   # Distillation loss weight

# Training settings
training:
  # Phases
  phase1_epochs: 10  # Pre-training with uniform weights
  phase2_epochs: 20  # RL policy learning
  phase3_epochs: 10  # Joint fine-tuning
  phase4_epochs: 10  # Meta-learning (optional)

  # Optimization
  optimizer: "adam"
  lr_student: 1.0e-4
  weight_decay: 3.0e-4
  momentum: 0.9

  # Learning rate schedule
  lr_scheduler: "cosine"
  warmup_epochs: 5
  min_lr: 1.0e-6

  # Gradient clipping
  clip_grad_norm: 1.0

# Evaluation settings
evaluation:
  metrics: ["mAP", "AP50", "AP75", "APs", "APm", "APl"]
  iou_thresholds: [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]
  max_dets: [1, 10, 100]

# Logging settings
logging:
  tensorboard: true
  wandb: false
  log_interval: 10
  save_dir: "experiments"
  checkpoint_dir: "experiments/checkpoints"
  log_dir: "experiments/logs"

# Visualization settings
visualization:
  enabled: true
  save_interval: 50
  plot_policy: true
  plot_gradnorm: true
  plot_rewards: true
